"""
RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ) å¼•æ“
å®ç°CSVçŸ¥è¯†åº“çš„ç²¾å‡†æ£€ç´¢ä¸ä¸Šä¸‹æ–‡æ³¨å…¥
"""

import pandas as pd
import streamlit as st
from typing import Dict, List, Optional, Tuple
import re


class IndustryRAGEngine:
    """
    è¡Œä¸šå‘¨æœŸçŸ¥è¯†åº“æ£€ç´¢å¼•æ“
    åŸºäºã€Šç»†åˆ†é¢†åŸŸè¡Œä¸šå‘¨æœŸç ”åˆ¤è¡¨.csvã€‹å®ç°ç²¾å‡†åŒ¹é…
    """
    
    def __init__(self, csv_path: str = "data/ç»†åˆ†é¢†åŸŸè¡Œä¸šå‘¨æœŸç ”åˆ¤è¡¨.csv"):
        """
        åˆå§‹åŒ–RAGå¼•æ“
        
        Args:
            csv_path: è¡Œä¸šå‘¨æœŸæ•°æ®CSVæ–‡ä»¶è·¯å¾„
        """
        self.csv_path = csv_path
        self.df = self._load_data()
        self.cycle_theory = self._load_cycle_theory()
    
    def _load_data(self) -> pd.DataFrame:
        """åŠ è½½å¹¶æ¸…æ´—è¡Œä¸šå‘¨æœŸæ•°æ®"""
        try:
            df = pd.read_csv(self.csv_path, encoding='utf-8')
            # æ¸…æ´—æ•°æ®
            df = df.loc[:, ~df.columns.str.contains('^Unnamed')]
            df = df.dropna(how='all')
            df = df.fillna("æš‚æ— è¯„ä»·")
            return df
        except Exception as e:
            st.error(f"åŠ è½½è¡Œä¸šæ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def _load_cycle_theory(self) -> Dict:
        """
        åŠ è½½é©¬æ±Ÿåšå‘¨æœŸç†è®ºæ˜ å°„
        æ ¹æ®å‘¨æœŸé˜¶æ®µè¿”å›å¯¹åº”çš„åº”å¯¹ç­–ç•¥
        """
        return {
            "åˆåˆ›æœŸ": {
                "ç‰¹å¾": "æŠ€æœ¯çªç ´ï¼Œå¸‚åœºæ•™è‚²é˜¶æ®µï¼Œæ¸—é€ç‡ä½äº5%",
                "æœºä¼š": "æ—©æœŸè¿›å…¥è€…å¯èƒ½è·å¾—è¶…é¢å›æŠ¥",
                "é£é™©": "æŠ€æœ¯è·¯çº¿ä¸ç¡®å®šï¼Œå¸‚åœºæ¥å—åº¦æœªçŸ¥",
                "ç­–ç•¥": "é€‚åˆé£é™©åå¥½é«˜ã€å­¦ä¹ èƒ½åŠ›å¼ºçš„æ±‚èŒè€…ï¼›å…³æ³¨æŠ€æœ¯è¿­ä»£å’Œèµ„æœ¬åŠ¨å‘",
                "å…¸å‹è¡Œä¸š": "ä½ç©ºç»æµã€è„‘æœºæ¥å£ã€é‡å­è®¡ç®—"
            },
            "æˆé•¿æœŸ": {
                "ç‰¹å¾": "æ¸—é€ç‡å¿«é€Ÿæå‡(5%-30%)ï¼Œèµ„æœ¬å¤§é‡æ¶Œå…¥",
                "æœºä¼š": "è¡Œä¸šçº¢åˆ©é‡Šæ”¾ï¼Œäººæ‰éœ€æ±‚çˆ†å‘",
                "é£é™©": "ç«äº‰åŠ å‰§ï¼ŒåæœŸè¿›å…¥è€…æˆæœ¬ä¸Šå‡",
                "ç­–ç•¥": "æœ€ä½³å…¥åœºæ—¶æœºï¼›é‡ç‚¹ç§¯ç´¯è¡Œä¸šæ ¸å¿ƒæŠ€èƒ½ï¼›é€‰æ‹©å¤´éƒ¨æˆ–é«˜æˆé•¿ä¼ä¸š",
                "å…¸å‹è¡Œä¸š": "äººå·¥æ™ºèƒ½ã€æ–°èƒ½æºæ±½è½¦ã€å‚¨èƒ½"
            },
            "æˆç†ŸæœŸ": {
                "ç‰¹å¾": "å¢é€Ÿæ”¾ç¼“ï¼Œç«äº‰æ ¼å±€ç¨³å®šï¼Œå¤´éƒ¨æ•ˆåº”æ˜æ˜¾",
                "æœºä¼š": "å²—ä½ç¨³å®šï¼Œè–ªèµ„åŸºå‡†è¾ƒé«˜",
                "é£é™©": "æ™‹å‡å¤©èŠ±æ¿æ˜æ˜¾ï¼Œå†…å·åŠ å‰§",
                "ç­–ç•¥": "æ·±è€•ç»†åˆ†é¢†åŸŸæˆä¸ºä¸“å®¶ï¼›æˆ–å‘ä¸Šä¸‹æ¸¸å»¶ä¼¸ï¼›å‚¨å¤‡è½¬å‹èƒ½åŠ›",
                "å…¸å‹è¡Œä¸š": "åŒ»è¯æµé€šã€ä¼ ç»Ÿæ¶ˆè´¹ç”µå­"
            },
            "è°ƒæ•´æœŸ": {
                "ç‰¹å¾": "äº§èƒ½è¿‡å‰©ï¼Œæ”¿ç­–æ”¶ç´§ï¼Œè¡Œä¸šæ´—ç‰Œ",
                "æœºä¼š": "å¹¶è´­æ•´åˆä¸­çš„ç®¡ç†å²—ä½",
                "é£é™©": "è£å‘˜é£é™©é«˜ï¼Œè–ªèµ„ä¸‹æ»‘",
                "ç­–ç•¥": "å°½æ—©è§„åˆ’è½¬å‹ï¼›å‘ç›¸å…³æˆé•¿æœŸè¡Œä¸šè¿ç§»æŠ€èƒ½ï¼›é¿å…é•¿æœŸåœç•™",
                "å…¸å‹è¡Œä¸š": "ä¼ ç»Ÿåœ°äº§ã€æ°´æ³¥ã€å…‰ä¼(å½“å‰)"
            },
            "è¡°é€€æœŸ": {
                "ç‰¹å¾": "éœ€æ±‚èç¼©ï¼Œæ”¿ç­–å‹é™ï¼Œäº§èƒ½å‡ºæ¸…",
                "æœºä¼š": "æå°‘",
                "é£é™©": "å¤±ä¸šé£é™©æé«˜",
                "ç­–ç•¥": "ç«‹å³å¯åŠ¨è½¬å‹ï¼›åˆ©ç”¨å¯è¿ç§»æŠ€èƒ½è½¬å‘ç›¸å…³è¡Œä¸š",
                "å…¸å‹è¡Œä¸š": "ä¼ ç»Ÿæ•™åŸ¹(åŒå‡å)ã€P2P"
            }
        }
    
    def search_industry(self, query: str, top_k: int = 3) -> List[Dict]:
        """
        æ£€ç´¢è¡Œä¸šä¿¡æ¯
        
        Args:
            query: ç”¨æˆ·è¾“å…¥çš„è¡Œä¸šåç§°æˆ–å…³é”®è¯
            top_k: è¿”å›æœ€ç›¸å…³çš„Kæ¡ç»“æœ
            
        Returns:
            åŒ¹é…çš„è¡Œä¸šä¿¡æ¯åˆ—è¡¨
        """
        if self.df.empty:
            return []
        
        results = []
        query_lower = query.lower()
        
        # 1. ç²¾ç¡®åŒ¹é…
        exact_match = self.df[self.df['è¡Œä¸šåç§°'].str.lower() == query_lower]
        if not exact_match.empty:
            for _, row in exact_match.iterrows():
                results.append(self._format_industry_record(row, match_type="ç²¾ç¡®åŒ¹é…"))
        
        # 2. åŒ…å«åŒ¹é…
        if len(results) < top_k:
            contain_match = self.df[
                self.df['è¡Œä¸šåç§°'].str.contains(query, case=False, na=False) &
                ~self.df['è¡Œä¸šåç§°'].str.lower().isin([r['è¡Œä¸šåç§°'].lower() for r in results])
            ]
            for _, row in contain_match.head(top_k - len(results)).iterrows():
                results.append(self._format_industry_record(row, match_type="åŒ…å«åŒ¹é…"))
        
        # 3. æ¨¡ç³ŠåŒ¹é…ï¼ˆå…³é”®è¯åˆ†å‰²ï¼‰
        if len(results) < top_k:
            keywords = re.findall(r'[\u4e00-\u9fff]+', query)
            for keyword in keywords:
                if len(keyword) >= 2:
                    fuzzy_match = self.df[
                        self.df['è¡Œä¸šåç§°'].str.contains(keyword, case=False, na=False) &
                        ~self.df['è¡Œä¸šåç§°'].str.lower().isin([r['è¡Œä¸šåç§°'].lower() for r in results])
                    ]
                    for _, row in fuzzy_match.head(top_k - len(results)).iterrows():
                        results.append(self._format_industry_record(row, match_type="ç›¸å…³åŒ¹é…"))
                    if len(results) >= top_k:
                        break
        
        return results[:top_k]
    
    def _format_industry_record(self, row: pd.Series, match_type: str = "") -> Dict:
        """æ ¼å¼åŒ–è¡Œä¸šè®°å½•"""
        stage = row.get('å½“å‰å‘¨æœŸé˜¶æ®µ', 'æœªçŸ¥')
        theory = self.cycle_theory.get(stage, {})
        
        return {
            "åºå·": row.get('åºå·', ''),
            "è¡Œä¸šåç§°": row.get('è¡Œä¸šåç§°', ''),
            "å½“å‰å‘¨æœŸé˜¶æ®µ": stage,
            "æœªæ¥1-3å¹´æ™¯æ°”åº¦": row.get('æœªæ¥1-3å¹´æ™¯æ°”åº¦', 'æœªçŸ¥'),
            "è¯„ä»·": row.get('è¯„ä»·', ''),
            "åŒ¹é…ç±»å‹": match_type,
            "ç†è®ºå»ºè®®": theory
        }
    
    def get_cycle_combination(self, industry_stage: str, policy_stage: str = None) -> Dict:
        """
        è·å–å‘¨æœŸç»„åˆç±»å‹
        
        Args:
            industry_stage: äº§ä¸šå‘¨æœŸé˜¶æ®µ
            policy_stage: æ”¿ç­–å‘¨æœŸé˜¶æ®µï¼ˆå¯é€‰ï¼‰
            
        Returns:
            ç»„åˆç±»å‹åŠå»ºè®®
        """
        # å››ç§å…¸å‹ç»„åˆ
        combinations = {
            ("åˆåˆ›æœŸ", "è§„åˆ’å¼•å¯¼æœŸ"): {
                "ç»„åˆåç§°": "é«˜é£é™©æŠ¼å®æœŸ",
                "é£é™©ç­‰çº§": "ğŸ”´ é«˜é£é™©",
                "ç‰¹å¾": "æŠ€æœ¯æœªéªŒè¯ + æ”¿ç­–åˆšå‡ºå°",
                "é€‚åˆäººç¾¤": "é£é™©åå¥½é«˜ã€æŠ—å‹èƒ½åŠ›å¼ºçš„æ—©æœŸæ¢ç´¢è€…",
                "ç­–ç•¥": "å°æ­¥è¯•é”™ï¼Œå…³æ³¨æŠ€æœ¯çªç ´ä¿¡å·"
            },
            ("æˆé•¿æœŸ", "èµ„æºèšç„¦æœŸ"): {
                "ç»„åˆåç§°": "çº¢åˆ©äº¤å æœŸ",
                "é£é™©ç­‰çº§": "ğŸŸ¢ æœ€ä½³æ—¶æœº",
                "ç‰¹å¾": "æ¸—é€ç‡å¿«é€Ÿæå‡ + æ”¿ç­–èµ„é‡‘æ¶Œå…¥",
                "é€‚åˆäººç¾¤": "ç»å¤§å¤šæ•°æ±‚èŒè€…ï¼Œå°¤å…¶æ˜¯è½¬å‹è€…",
                "ç­–ç•¥": "æœæ–­å…¥åœºï¼Œç§¯ç´¯æ ¸å¿ƒæŠ€èƒ½ï¼Œé€‰æ‹©é«˜æˆé•¿ä¼ä¸š"
            },
            ("æˆç†ŸæœŸ", "è°ƒæ•´é€€å‡ºæœŸ"): {
                "ç»„åˆåç§°": "çº¢åˆ©é€€å¡æœŸ",
                "é£é™©ç­‰çº§": "ğŸŸ¡ è°¨æ…",
                "ç‰¹å¾": "å¢é€Ÿæ”¾ç¼“ + æ”¿ç­–æ”¶ç´§",
                "é€‚åˆäººç¾¤": "è¿½æ±‚ç¨³å®šçš„èµ„æ·±ä»ä¸šè€…",
                "ç­–ç•¥": "é˜²å¾¡æ€§è§„åˆ’ï¼Œå‚¨å¤‡è½¬å‹èƒ½åŠ›ï¼Œå…³æ³¨ç»†åˆ†æœºä¼š"
            },
            ("è°ƒæ•´æœŸ", "æ”¿ç­–å‹é™æœŸ"): {
                "ç»„åˆåç§°": "çº¢åˆ©æ¶ˆå¤±æœŸ",
                "é£é™©ç­‰çº§": "ğŸ”´ é«˜å±",
                "ç‰¹å¾": "äº§èƒ½è¿‡å‰© + æ˜ç¡®é™åˆ¶",
                "é€‚åˆäººç¾¤": "ä¸å»ºè®®è¿›å…¥",
                "ç­–ç•¥": "å°½æ—©ç¦»åœºï¼Œåˆ©ç”¨å¯è¿ç§»æŠ€èƒ½è½¬å‹"
            },
            ("è¡°é€€æœŸ", "æ”¿ç­–å‹é™æœŸ"): {
                "ç»„åˆåç§°": "çº¢åˆ©æ¶ˆå¤±æœŸ",
                "é£é™©ç­‰çº§": "ğŸ”´ é«˜å±",
                "ç‰¹å¾": "éœ€æ±‚èç¼© + æ”¿ç­–å‡ºæ¸…",
                "é€‚åˆäººç¾¤": "ä¸å»ºè®®è¿›å…¥",
                "ç­–ç•¥": "ç«‹å³å¯åŠ¨è½¬å‹è®¡åˆ’"
            }
        }
        
        # å°è¯•åŒ¹é…
        if policy_stage:
            key = (industry_stage, policy_stage)
            if key in combinations:
                return combinations[key]
        
        # åŸºäºäº§ä¸šå‘¨æœŸé˜¶æ®µè¿”å›é»˜è®¤å»ºè®®
        stage_advice = {
            "åˆåˆ›æœŸ": combinations.get(("åˆåˆ›æœŸ", "è§„åˆ’å¼•å¯¼æœŸ")),
            "æˆé•¿æœŸ": combinations.get(("æˆé•¿æœŸ", "èµ„æºèšç„¦æœŸ")),
            "æˆç†ŸæœŸ": combinations.get(("æˆç†ŸæœŸ", "è°ƒæ•´é€€å‡ºæœŸ")),
            "è°ƒæ•´æœŸ": combinations.get(("è°ƒæ•´æœŸ", "æ”¿ç­–å‹é™æœŸ")),
            "è¡°é€€æœŸ": combinations.get(("è¡°é€€æœŸ", "æ”¿ç­–å‹é™æœŸ"))
        }
        
        return stage_advice.get(industry_stage, {
            "ç»„åˆåç§°": "æœªçŸ¥ç»„åˆ",
            "é£é™©ç­‰çº§": "âšª æœªçŸ¥",
            "ç‰¹å¾": "æ— æ³•åˆ¤æ–­",
            "é€‚åˆäººç¾¤": "æœªçŸ¥",
            "ç­–ç•¥": "å»ºè®®è¿›ä¸€æ­¥è°ƒç ”"
        })
    
    def build_context_for_llm(self, industry_name: str) -> str:
        """
        ä¸ºLLMæ„å»ºæ£€ç´¢ä¸Šä¸‹æ–‡
        
        Args:
            industry_name: è¡Œä¸šåç§°
            
        Returns:
            æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡æ–‡æœ¬
        """
        search_results = self.search_industry(industry_name, top_k=2)
        
        if not search_results:
            return f"æœªåœ¨çŸ¥è¯†åº“ä¸­æ‰¾åˆ°'{industry_name}'çš„ç›¸å…³ä¿¡æ¯ã€‚è¯·åŸºäºé€šç”¨å‘¨æœŸç†è®ºè¿›è¡Œåˆ†æã€‚"
        
        context_parts = []
        context_parts.append(f"ã€çŸ¥è¯†åº“æ£€ç´¢ç»“æœã€‘ç”¨æˆ·å…³æ³¨è¡Œä¸šï¼š{industry_name}\n")
        
        for i, result in enumerate(search_results, 1):
            context_parts.append(f"\n--- åŒ¹é…ç»“æœ {i} ({result['åŒ¹é…ç±»å‹']}) ---")
            context_parts.append(f"è¡Œä¸šåç§°ï¼š{result['è¡Œä¸šåç§°']}")
            context_parts.append(f"å½“å‰å‘¨æœŸé˜¶æ®µï¼š{result['å½“å‰å‘¨æœŸé˜¶æ®µ']}")
            context_parts.append(f"æœªæ¥1-3å¹´æ™¯æ°”åº¦ï¼š{result['æœªæ¥1-3å¹´æ™¯æ°”åº¦']}")
            context_parts.append(f"è¯„ä»·ï¼š{result['è¯„ä»·']}")
            
            # æ·»åŠ å‘¨æœŸç†è®ºå»ºè®®
            theory = result.get('ç†è®ºå»ºè®®', {})
            if theory:
                context_parts.append(f"\nå‘¨æœŸç†è®ºæŒ‡å¯¼ï¼š")
                context_parts.append(f"- é˜¶æ®µç‰¹å¾ï¼š{theory.get('ç‰¹å¾', '')}")
                context_parts.append(f"- æœºä¼šåˆ†æï¼š{theory.get('æœºä¼š', '')}")
                context_parts.append(f"- é£é™©æç¤ºï¼š{theory.get('é£é™©', '')}")
                context_parts.append(f"- åº”å¯¹ç­–ç•¥ï¼š{theory.get('ç­–ç•¥', '')}")
            
            # æ·»åŠ ç»„åˆç±»å‹åˆ†æ
            combo = self.get_cycle_combination(result['å½“å‰å‘¨æœŸé˜¶æ®µ'])
            context_parts.append(f"\nå‘¨æœŸç»„åˆç ”åˆ¤ï¼š")
            context_parts.append(f"- ç»„åˆç±»å‹ï¼š{combo.get('ç»„åˆåç§°', '')} {combo.get('é£é™©ç­‰çº§', '')}")
            context_parts.append(f"- é€‚åˆäººç¾¤ï¼š{combo.get('é€‚åˆäººç¾¤', '')}")
            context_parts.append(f"- è¡ŒåŠ¨å»ºè®®ï¼š{combo.get('ç­–ç•¥', '')}")
        
        context_parts.append("\n--- åˆ†æè¦æ±‚ ---")
        context_parts.append("è¯·åŸºäºä»¥ä¸ŠçŸ¥è¯†åº“æ•°æ®ï¼Œç»“åˆé©¬æ±Ÿåšå‘¨æœŸç†è®ºï¼Œä¸ºç”¨æˆ·æä¾›æœ‰ç†æœ‰æ®çš„èŒä¸šè§„åˆ’å»ºè®®ã€‚")
        context_parts.append("é¿å…ä½¿ç”¨å¤§è¯å¥—è¯ï¼Œæ‰€æœ‰å»ºè®®å¿…é¡»åŸºäºä¸Šè¿°æ•°æ®æ”¯æ’‘ã€‚")
        
        return "\n".join(context_parts)
    
    def get_risk_warning(self, industry_name: str) -> Optional[Dict]:
        """
        è·å–è¡Œä¸šé£é™©é¢„è­¦
        
        Args:
            industry_name: è¡Œä¸šåç§°
            
        Returns:
            é£é™©é¢„è­¦ä¿¡æ¯ï¼Œå¦‚æ— é£é™©åˆ™è¿”å›None
        """
        results = self.search_industry(industry_name, top_k=1)
        if not results:
            return None
        
        result = results[0]
        stage = result['å½“å‰å‘¨æœŸé˜¶æ®µ']
        sentiment = result['æœªæ¥1-3å¹´æ™¯æ°”åº¦']
        
        # å®šä¹‰é£é™©ç­‰çº§
        if stage in ['è°ƒæ•´æœŸ', 'è¡°é€€æœŸ'] or 'æ‰¿å‹' in sentiment:
            return {
                "é£é™©ç­‰çº§": "ğŸ”´ é«˜é£é™©",
                "é¢„è­¦ç±»å‹": "è¡Œä¸šå¤„äºä¸‹è¡Œå‘¨æœŸ",
                "å½“å‰é˜¶æ®µ": stage,
                "æ™¯æ°”åº¦": sentiment,
                "å»ºè®®": "å»ºè®®å°½æ—©è§„åˆ’è½¬å‹ï¼Œåˆ©ç”¨ç°æœ‰æŠ€èƒ½å‘æˆé•¿æœŸè¡Œä¸šè¿ç§»",
                "æ¨èæ–¹å‘": self._get_transition_recommendations(industry_name)
            }
        elif stage == 'æˆç†ŸæœŸ' and 'å¹³ç¨³' in sentiment:
            return {
                "é£é™©ç­‰çº§": "ğŸŸ¡ ä¸­ç­‰é£é™©",
                "é¢„è­¦ç±»å‹": "è¡Œä¸šå¢é•¿æ”¾ç¼“",
                "å½“å‰é˜¶æ®µ": stage,
                "æ™¯æ°”åº¦": sentiment,
                "å»ºè®®": "å»ºè®®åšå¥½é˜²å¾¡æ€§è§„åˆ’ï¼Œå‚¨å¤‡è½¬å‹èƒ½åŠ›",
                "æ¨èæ–¹å‘": []
            }
        
        return None
    
    def _get_transition_recommendations(self, current_industry: str) -> List[Dict]:
        """
        è·å–è½¬å‹æ¨èæ–¹å‘
        
        Args:
            current_industry: å½“å‰è¡Œä¸š
            
        Returns:
            æ¨èçš„è½¬å‹æ–¹å‘åˆ—è¡¨
        """
        if self.df.empty:
            return []
        
        # è·å–æˆé•¿æœŸè¡Œä¸šä½œä¸ºæ¨è
        growth_industries = self.df[
            self.df['å½“å‰å‘¨æœŸé˜¶æ®µ'].isin(['æˆé•¿æœŸ', 'åˆåˆ›æœŸ']) &
            self.df['æœªæ¥1-3å¹´æ™¯æ°”åº¦'].str.contains('é«˜æˆé•¿|é«˜', na=False)
        ].head(5)
        
        recommendations = []
        for _, row in growth_industries.iterrows():
            recommendations.append({
                "è¡Œä¸šåç§°": row['è¡Œä¸šåç§°'],
                "å‘¨æœŸé˜¶æ®µ": row['å½“å‰å‘¨æœŸé˜¶æ®µ'],
                "æ™¯æ°”åº¦": row['æœªæ¥1-3å¹´æ™¯æ°”åº¦'],
                "æ¨èç†ç”±": row['è¯„ä»·']
            })
        
        return recommendations


@st.cache_resource
def get_rag_engine() -> IndustryRAGEngine:
    """è·å–RAGå¼•æ“å•ä¾‹ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    return IndustryRAGEngine()
