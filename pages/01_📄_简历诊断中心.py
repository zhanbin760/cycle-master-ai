import streamlit as st
import re
import sys
import os

# ç¡®ä¿èƒ½æ­£ç¡®å¼•å…¥ utils æ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils.llm_engine import render_api_key_input, render_privacy_notice, get_deepseek_client, increment_usage
from utils.rag_engine import get_rag_engine
from utils.data_processor import load_industry_data, get_growth_industries

st.set_page_config(page_title="ç®€å†è¯Šæ–­ä¸­å¿ƒ", page_icon="ğŸ“„", layout="wide")

st.title("ğŸ“„ ç®€å†è¯Šæ–­ä¸­å¿ƒï¼šAIè¯†åˆ«è¡Œä¸šé£é™©å¹¶æ¨èæ–¹å‘")
st.markdown("ç²˜è´´æ‚¨çš„ç®€å†å†…å®¹ï¼ŒAIå°†æå–æ‚¨çš„è¿‡å¾€è¡Œä¸šç»å†ï¼Œè‡ªåŠ¨ä¸å‘¨æœŸæ•°æ®åº“å¯¹æ¯”ï¼Œè¯†åˆ«é£é™©å¹¶æ¨èé€‚åˆçš„è½¬å‹æ–¹å‘ã€‚")

# æ¸²æŸ“ API Key å’Œéšç§å£°æ˜
render_api_key_input()
render_privacy_notice()

# ==========================================
# éšç§æç¤º
# ==========================================
st.info("ğŸ”’ **éšç§å£°æ˜**ï¼šç²˜è´´çš„ç®€å†å†…å®¹ä»…ç”¨äºæœ¬æ¬¡åˆ†æï¼Œä¸ä¼šè¢«å­˜å‚¨ã€‚æ‰€æœ‰æ•°æ®å¤„ç†åœ¨ä¼šè¯ç»“æŸåç«‹å³æ¸…é™¤ã€‚")

# ==========================================
# ç®€å†ç²˜è´´åŒºåŸŸ
# ==========================================
st.markdown("### âœï¸ ç²˜è´´ç®€å†å†…å®¹")

resume_text = st.text_area(
    "è¯·ç²˜è´´æ‚¨çš„ç®€å†å†…å®¹ï¼ˆå·¥ä½œç»å†ã€é¡¹ç›®ç»éªŒç­‰ï¼‰ï¼š",
    height=300,
    placeholder="""ä¾‹å¦‚ï¼š
ã€å·¥ä½œç»å†ã€‘
2018.06 - 2022.03  æŸåœ°äº§å…¬å¸  é¡¹ç›®ç»ç†
è´Ÿè´£æˆ¿åœ°äº§å¼€å‘é¡¹ç›®çš„å…¨æµç¨‹ç®¡ç†ï¼ŒåŒ…æ‹¬è§„åˆ’è®¾è®¡ã€æ–½å·¥ç›‘ç†ã€æˆæœ¬æ§åˆ¶ç­‰ã€‚

2022.04 - è‡³ä»Š    æŸå»ºç­‘å…¬å¸  é«˜çº§å·¥ç¨‹å¸ˆ
è´Ÿè´£å»ºç­‘ç»“æ„è®¾è®¡ï¼Œå‚ä¸å¤šä¸ªå¤§å‹å•†ä¸šç»¼åˆä½“é¡¹ç›®ã€‚

ã€æ•™è‚²èƒŒæ™¯ã€‘
2014.09 - 2018.06  æŸå¤§å­¦  åœŸæœ¨å·¥ç¨‹  æœ¬ç§‘

ã€æŠ€èƒ½ã€‘
é¡¹ç›®ç®¡ç†ã€AutoCADã€ç»“æ„è®¾è®¡ã€æˆæœ¬æ§åˆ¶
"""
)

# ==========================================
# å¿«é€Ÿè¡Œä¸šé€‰æ‹©ï¼ˆå¯é€‰ï¼‰
# ==========================================
st.markdown("### ğŸ­ æˆ–é€‰æ‹©æ‚¨æ‰€åœ¨çš„è¡Œä¸š")

# å¸¸ç”¨è¡Œä¸šåˆ—è¡¨
common_industries = [
    "æˆ¿åœ°äº§", "å»ºç­‘", "äº’è”ç½‘", "é‡‘è", "åˆ¶é€ ä¸š", 
    "æ•™è‚²", "åŒ»ç–—", "é›¶å”®", "èƒ½æº", "ä¼ åª’"
]

col1, col2 = st.columns(2)
with col1:
    selected_industry = st.selectbox(
        "é€‰æ‹©æ‚¨æ‰€åœ¨çš„è¡Œä¸šï¼ˆå¯é€‰ï¼‰ï¼š",
        ["è‡ªåŠ¨è¯†åˆ«"] + common_industries + ["å…¶ä»–"]
    )

with col2:
    if selected_industry == "å…¶ä»–":
        custom_industry = st.text_input("è¯·è¾“å…¥æ‚¨çš„è¡Œä¸šï¼š")
    else:
        custom_industry = ""

# ==========================================
# ç®€å†è§£æå‡½æ•°
# ==========================================
def parse_resume_with_llm(resume_text: str) -> dict:
    """ä½¿ç”¨LLMè§£æç®€å†å†…å®¹"""
    if not resume_text or len(resume_text.strip()) < 20:
        return {"error": "ç®€å†å†…å®¹å¤ªçŸ­ï¼Œæ— æ³•è§£æ"}
    
    client = get_deepseek_client()
    
    prompt = f"""è¯·ä»ä»¥ä¸‹ç®€å†ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œä»¥JSONæ ¼å¼è¿”å›ï¼š

ç®€å†å†…å®¹ï¼š
{resume_text[:4000]}

è¯·æå–ä»¥ä¸‹å­—æ®µï¼š
1. industries: è¡Œä¸šç»å†åˆ—è¡¨ï¼ˆæ¯ä¸ªåŒ…å« nameè¡Œä¸šåç§°, periodæ—¶é—´æ®µ, roleèŒä½ï¼‰
2. skills: æ ¸å¿ƒæŠ€èƒ½åˆ—è¡¨ï¼ˆå­—ç¬¦ä¸²æ•°ç»„ï¼‰
3. total_years: å·¥ä½œå¹´é™ï¼ˆæ•°å­—æˆ–å­—ç¬¦ä¸²ï¼‰
4. education: æœ€é«˜å­¦å†
5. current_role: å½“å‰/æœ€è¿‘èŒä½

æ³¨æ„ï¼š
- å¦‚æœæ‰¾ä¸åˆ°æŸå­—æ®µï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²æˆ–ç©ºæ•°ç»„
- è¡Œä¸šåç§°è¯·å°½é‡æ ‡å‡†ï¼Œå¦‚"æˆ¿åœ°äº§"ã€"äº’è”ç½‘"ã€"é‡‘è"ç­‰
- å¿…é¡»è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼

è¿”å›ç¤ºä¾‹ï¼š
{{
    "industries": [
        {{"name": "æˆ¿åœ°äº§", "period": "2018-2022", "role": "é¡¹ç›®ç»ç†"}},
        {{"name": "å»ºç­‘", "period": "2022-è‡³ä»Š", "role": "é«˜çº§å·¥ç¨‹å¸ˆ"}}
    ],
    "skills": ["é¡¹ç›®ç®¡ç†", "å·¥ç¨‹ç®¡ç†", "å›¢é˜Ÿåè°ƒ"],
    "total_years": "6å¹´",
    "education": "æœ¬ç§‘",
    "current_role": "é«˜çº§å·¥ç¨‹å¸ˆ"
}}"""
    
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç®€å†è§£æåŠ©æ‰‹ï¼Œæ“…é•¿ä»ç®€å†ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯ï¼Œåªè¿”å›JSONæ ¼å¼ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=1500
        )
        
        import json
        result_text = response.choices[0].message.content
        
        # å°è¯•æå–JSON
        try:
            # æŸ¥æ‰¾JSONä»£ç å—
            json_block = re.search(r'```json\s*(.*?)\s*```', result_text, re.DOTALL)
            if json_block:
                return json.loads(json_block.group(1))
            
            # æŸ¥æ‰¾æ™®é€šJSONå¯¹è±¡
            json_match = re.search(r'\{[\s\S]*\}', result_text)
            if json_match:
                return json.loads(json_match.group())
            
            # ç›´æ¥è§£æ
            return json.loads(result_text)
        except json.JSONDecodeError:
            return {
                "industries": [],
                "skills": [],
                "parse_error": True,
                "raw_response": result_text
            }
            
    except Exception as e:
        return {"error": str(e)}


def extract_industries_from_text(text: str) -> list:
    """ä»æ–‡æœ¬ä¸­æå–è¡Œä¸šå…³é”®è¯ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
    industry_keywords = {
        "æˆ¿åœ°äº§": ["æˆ¿åœ°äº§", "åœ°äº§", "ç½®ä¸š", "ä¸‡ç§‘", "ç¢§æ¡‚å›­", "æ’å¤§"],
        "å»ºç­‘": ["å»ºç­‘", "æ–½å·¥", "åŸºå»º", "ä¸­å»º", "ä¸­é“", "æ‰¿åŒ…å•†"],
        "äº’è”ç½‘": ["äº’è”ç½‘", "IT", "è½¯ä»¶", "é˜¿é‡Œ", "è…¾è®¯", "å­—èŠ‚", "ç¾å›¢"],
        "é‡‘è": ["é‡‘è", "é“¶è¡Œ", "è¯åˆ¸", "ä¿é™©", "åŸºé‡‘", "æŠ•èµ„"],
        "åˆ¶é€ ä¸š": ["åˆ¶é€ ", "ç”Ÿäº§", "å·¥å‚", "å·¥ä¸š", "æ±½è½¦", "ç”µå­"],
        "æ•™è‚²": ["æ•™è‚²", "åŸ¹è®­", "å­¦æ ¡", "æ•™åŸ¹", "æ–°ä¸œæ–¹", "å­¦è€Œæ€"],
        "åŒ»ç–—": ["åŒ»ç–—", "åŒ»è¯", "åŒ»é™¢", "åˆ¶è¯", "å™¨æ¢°", "å¥åº·"],
        "é›¶å”®": ["é›¶å”®", "ç”µå•†", "è¶…å¸‚", "å•†åœº", "é”€å”®", "è´¸æ˜“"],
        "èƒ½æº": ["èƒ½æº", "ç”µåŠ›", "çŸ³æ²¹", "ç…¤ç‚­", "æ–°èƒ½æº", "å…‰ä¼"],
        "ä¼ åª’": ["ä¼ åª’", "å¹¿å‘Š", "åª’ä½“", "å½±è§†", "å‡ºç‰ˆ", "æ–°é—»"],
    }
    
    found_industries = []
    for industry, keywords in industry_keywords.items():
        for keyword in keywords:
            if keyword in text:
                found_industries.append(industry)
                break
    
    return list(set(found_industries))  # å»é‡


# ==========================================
# è¡Œä¸šé£é™©åˆ†æ
# ==========================================
def analyze_industry_risks(industries: list) -> dict:
    """åˆ†æè¡Œä¸šé£é™©"""
    rag_engine = get_rag_engine()
    
    risk_analysis = {
        "é«˜é£é™©": [],
        "ä¸­é£é™©": [],
        "ä½é£é™©": [],
        "æœªè¯†åˆ«": []
    }
    
    for industry in industries:
        results = rag_engine.search_industry(industry, top_k=1)
        if results:
            result = results[0]
            stage = result['å½“å‰å‘¨æœŸé˜¶æ®µ']
            sentiment = result['æœªæ¥1-3å¹´æ™¯æ°”åº¦']
            
            if stage in ['è°ƒæ•´æœŸ', 'è¡°é€€æœŸ'] or 'æ‰¿å‹' in sentiment:
                risk_analysis["é«˜é£é™©"].append({
                    "industry": industry,
                    "stage": stage,
                    "sentiment": sentiment,
                    "warning": rag_engine.get_risk_warning(industry)
                })
            elif stage == 'æˆç†ŸæœŸ' and 'å¹³ç¨³' in sentiment:
                risk_analysis["ä¸­é£é™©"].append({
                    "industry": industry,
                    "stage": stage,
                    "sentiment": sentiment
                })
            else:
                risk_analysis["ä½é£é™©"].append({
                    "industry": industry,
                    "stage": stage,
                    "sentiment": sentiment
                })
        else:
            risk_analysis["æœªè¯†åˆ«"].append(industry)
    
    return risk_analysis


# ==========================================
# æ¨èè½¬å‹æ–¹å‘
# ==========================================
def get_transition_recommendations(current_industries: list, skills: list = None) -> list:
    """è·å–è½¬å‹æ¨è"""
    rag_engine = get_rag_engine()
    df = load_industry_data()
    
    growth_industries = get_growth_industries(df)
    
    recommendations = []
    
    # è¡Œä¸šæ˜ å°„å…³ç³»
    skill_mappings = {
        "æˆ¿åœ°äº§": ["æ™ºæ…§åŸå¸‚", "å…»è€äº§ä¸š", "ç‰©ä¸šç®¡ç†", "æˆ¿åœ°äº§ç§‘æŠ€"],
        "å»ºç­‘": ["å…‰ä¼åŸºå»º", "å‚¨èƒ½", "è™šæ‹Ÿç”µå‚", "æ™ºèƒ½å»ºé€ "],
        "ä¼ ç»Ÿåˆ¶é€ ": ["æ™ºèƒ½åˆ¶é€ ", "å·¥ä¸šæœºå™¨äºº", "æ–°èƒ½æºè£…å¤‡", "åŠå¯¼ä½“è®¾å¤‡"],
        "æ•™åŸ¹": ["èŒä¸šæ•™è‚²", "ä¼ä¸šåŸ¹è®­", "çŸ¥è¯†ä»˜è´¹", "æ•™è‚²ç§‘æŠ€"],
        "äº’è”ç½‘": ["äººå·¥æ™ºèƒ½", "SaaS", "äº§ä¸šäº’è”ç½‘", "äº‘è®¡ç®—"],
        "é‡‘è": ["é‡‘èç§‘æŠ€", "ç»¿è‰²é‡‘è", "æ•°å­—äººæ°‘å¸", "åŒºå—é“¾é‡‘è"],
        "ä¼ åª’": ["çŸ­è§†é¢‘", "ç›´æ’­ç”µå•†", "AIGCå†…å®¹", "æ•°å­—è¥é”€"],
        "èƒ½æº": ["æ–°èƒ½æº", "å‚¨èƒ½", "æ°¢èƒ½", "ç¢³ä¸­å’Œ"],
        "é›¶å”®": ["ç”µå•†", "ç›´æ’­å¸¦è´§", "è·¨å¢ƒç”µå•†", "æ–°é›¶å”®"],
        "åŒ»ç–—": ["ç”Ÿç‰©åŒ»è¯", "åŒ»ç–—å™¨æ¢°", "æ•°å­—åŒ»ç–—", "AIåŒ»ç–—"]
    }
    
    for industry in current_industries:
        for key, targets in skill_mappings.items():
            if key in industry:
                for target in targets:
                    target_data = rag_engine.search_industry(target, top_k=1)
                    if target_data:
                        cycle_stage = target_data[0]['å½“å‰å‘¨æœŸé˜¶æ®µ']
                        if cycle_stage in ['æˆé•¿æœŸ', 'åˆåˆ›æœŸ']:
                            recommendations.append({
                                "from": industry,
                                "to": target,
                                "reason": f"{key}è¡Œä¸šç»éªŒå¯è¿ç§»è‡³{target}",
                                "cycle_stage": cycle_stage,
                                "sentiment": target_data[0]['æœªæ¥1-3å¹´æ™¯æ°”åº¦']
                            })
    
    # å¦‚æœæ²¡æœ‰ç‰¹å®šåŒ¹é…ï¼Œè¿”å›é€šç”¨æ¨è
    if not recommendations:
        for ind in growth_industries[:5]:
            recommendations.append({
                "from": current_industries[0] if current_industries else "å½“å‰è¡Œä¸š",
                "to": ind['è¡Œä¸šåç§°'],
                "reason": "å½“å‰å¤„äºæˆé•¿æœŸï¼Œäººæ‰éœ€æ±‚æ—ºç››",
                "cycle_stage": ind['å‘¨æœŸé˜¶æ®µ'],
                "sentiment": ind['æ™¯æ°”åº¦']
            })
    
    # å»é‡
    seen = set()
    unique_recommendations = []
    for rec in recommendations:
        if rec['to'] not in seen:
            seen.add(rec['to'])
            unique_recommendations.append(rec)
    
    return unique_recommendations[:5]


# ==========================================
# è¯Šæ–­æŒ‰é’®
# ==========================================
st.markdown("---")

if st.button("ğŸ” å¼€å§‹ç®€å†è¯Šæ–­", use_container_width=True, type="primary"):
    # ç¡®å®šä½¿ç”¨çš„è¡Œä¸šä¿¡æ¯
    if selected_industry == "è‡ªåŠ¨è¯†åˆ«":
        industries_from_select = []
    elif selected_industry == "å…¶ä»–":
        industries_from_select = [custom_industry] if custom_industry else []
    else:
        industries_from_select = [selected_industry]
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¾“å…¥
    if not resume_text.strip() and not industries_from_select:
        st.error("âš ï¸ è¯·ç²˜è´´ç®€å†å†…å®¹æˆ–é€‰æ‹©æ‚¨æ‰€åœ¨çš„è¡Œä¸š")
    else:
        with st.spinner("æ­£åœ¨åˆ†æç®€å†å¹¶è¯†åˆ«è¡Œä¸šé£é™©..."):
            try:
                increment_usage()
                
                # è§£æç®€å†
                if resume_text.strip():
                    st.info("ğŸ“ æ­£åœ¨è§£æç®€å†å†…å®¹...")
                    parsed = parse_resume_with_llm(resume_text)
                    
                    # å¦‚æœLLMè§£æå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
                    if parsed.get("error") or parsed.get("parse_error"):
                        st.warning("ä½¿ç”¨å¤‡ç”¨è¯†åˆ«æ–¹æ¡ˆ...")
                        extracted = extract_industries_from_text(resume_text)
                        parsed = {
                            "industries": [{"name": ind, "period": "", "role": ""} for ind in extracted],
                            "skills": [],
                            "total_years": "",
                            "education": "",
                            "current_role": ""
                        }
                else:
                    parsed = {"industries": [], "skills": [], "total_years": "", "education": "", "current_role": ""}
                
                # åˆå¹¶è¡Œä¸šä¿¡æ¯
                parsed_industries = [ind.get("name", "") for ind in parsed.get("industries", []) if isinstance(ind, dict)]
                all_industries = list(set(industries_from_select + parsed_industries))
                
                # æ˜¾ç¤ºè§£æç»“æœ
                st.markdown("---")
                st.markdown("### ğŸ“‹ è§£æç»“æœ")
                
                result_cols = st.columns(2)
                
                with result_cols[0]:
                    st.markdown("**ğŸ¯ è¯†åˆ«åˆ°çš„è¡Œä¸šï¼š**")
                    if all_industries:
                        for ind in all_industries:
                            st.markdown(f"- **{ind}**")
                    else:
                        st.markdown("*æœªèƒ½è¯†åˆ«åˆ°è¡Œä¸šä¿¡æ¯*")
                    
                    if parsed.get("total_years"):
                        st.markdown(f"\n**â±ï¸ å·¥ä½œå¹´é™ï¼š** {parsed['total_years']}")
                    if parsed.get("current_role"):
                        st.markdown(f"**ğŸ’¼ å½“å‰èŒä½ï¼š** {parsed['current_role']}")
                
                with result_cols[1]:
                    st.markdown("**ğŸ› ï¸ è¯†åˆ«åˆ°çš„æŠ€èƒ½ï¼š**")
                    skills = parsed.get("skills", [])
                    if skills:
                        for skill in skills[:10]:  # æœ€å¤šæ˜¾ç¤º10ä¸ª
                            st.markdown(f"- {skill}")
                    else:
                        st.markdown("*æœªèƒ½è¯†åˆ«åˆ°æŠ€èƒ½ä¿¡æ¯*")
                
                # é£é™©åˆ†æ
                if all_industries:
                    st.markdown("---")
                    st.markdown("### âš ï¸ è¡Œä¸šé£é™©åˆ†æ")
                    
                    risk_analysis = analyze_industry_risks(all_industries)
                    
                    risk_cols = st.columns(4)
                    
                    with risk_cols[0]:
                        count = len(risk_analysis['é«˜é£é™©'])
                        st.error(f"ğŸ”´ é«˜é£é™©ï¼š{count} ä¸ª")
                    with risk_cols[1]:
                        count = len(risk_analysis['ä¸­é£é™©'])
                        st.warning(f"ğŸŸ¡ ä¸­é£é™©ï¼š{count} ä¸ª")
                    with risk_cols[2]:
                        count = len(risk_analysis['ä½é£é™©'])
                        st.success(f"ğŸŸ¢ ä½é£é™©ï¼š{count} ä¸ª")
                    with risk_cols[3]:
                        count = len(risk_analysis['æœªè¯†åˆ«'])
                        st.info(f"âšª æœªè¯†åˆ«ï¼š{count} ä¸ª")
                    
                    # è¯¦ç»†é£é™©ä¿¡æ¯
                    if risk_analysis["é«˜é£é™©"]:
                        st.markdown("---")
                        st.error("ğŸš¨ **çº¢è‰²é¢„è­¦ï¼šæ£€æµ‹åˆ°é«˜é£é™©è¡Œä¸šï¼**")
                        
                        for item in risk_analysis["é«˜é£é™©"]:
                            warning = item.get('warning', {})
                            with st.container(border=True):
                                st.markdown(f"**{item['industry']}** - {item['stage']}")
                                st.markdown(f"æ™¯æ°”åº¦ï¼š**{item['sentiment']}**")
                                if warning:
                                    st.markdown(f"ğŸ’¡ **å»ºè®®**ï¼š{warning.get('å»ºè®®', 'å»ºè®®å°½æ—©è§„åˆ’è½¬å‹')}")
                                    
                                    # æ˜¾ç¤ºæ¨èè½¬å‹æ–¹å‘
                                    if warning.get('æ¨èæ–¹å‘'):
                                        st.markdown("**æ¨èæ–¹å‘**ï¼š")
                                        for rec in warning['æ¨èæ–¹å‘'][:3]:
                                            st.markdown(f"- {rec['è¡Œä¸šåç§°']}ï¼ˆ{rec['å‘¨æœŸé˜¶æ®µ']}ï¼‰")
                    
                    if risk_analysis["ä¸­é£é™©"]:
                        with st.expander(f"ğŸŸ¡ ä¸­é£é™©è¡Œä¸šè¯¦æƒ… ({len(risk_analysis['ä¸­é£é™©'])}ä¸ª)"):
                            for item in risk_analysis["ä¸­é£é™©"]:
                                st.markdown(f"- **{item['industry']}**ï¼š{item['stage']}ï¼Œ{item['sentiment']}")
                    
                    # è½¬å‹æ¨è
                    st.markdown("---")
                    st.markdown("### ğŸ¯ è½¬å‹æ¨èæ–¹å‘")
                    
                    recommendations = get_transition_recommendations(all_industries, skills)
                    
                    if recommendations:
                        st.success("åŸºäºæ‚¨çš„è¡Œä¸šèƒŒæ™¯å’Œå‘¨æœŸæ•°æ®ï¼Œæ¨èä»¥ä¸‹è½¬å‹æ–¹å‘ï¼š")
                        
                        for i, rec in enumerate(recommendations, 1):
                            with st.container(border=True):
                                cols = st.columns([3, 1])
                                with cols[0]:
                                    st.markdown(f"#### {i}. **{rec['to']}**")
                                    st.markdown(f"- **æ¨èç†ç”±**ï¼š{rec['reason']}")
                                    st.markdown(f"- **å‘¨æœŸé˜¶æ®µ**ï¼š{rec['cycle_stage']} | **æ™¯æ°”åº¦**ï¼š{rec['sentiment']}")
                                with cols[1]:
                                    if st.button(f"æŸ¥çœ‹è¯¦æƒ…", key=f"btn_detail_{i}"):
                                        st.session_state['target_industry'] = rec['to']
                                        st.switch_page("pages/03_ğŸ¤–_AIååŒè§„åˆ’å®˜.py")
                    else:
                        st.info("æœªèƒ½ç”Ÿæˆè½¬å‹æ¨èï¼Œå»ºè®®å’¨è¯¢AIè§„åˆ’å®˜è·å–ä¸ªæ€§åŒ–å»ºè®®")
                    
                    # AIæ·±åº¦åˆ†æ
                    st.markdown("---")
                    st.markdown("### ğŸ¤– AIæ·±åº¦åˆ†ææŠ¥å‘Š")
                    
                    with st.spinner("æ­£åœ¨ç”Ÿæˆæ·±åº¦åˆ†ææŠ¥å‘Š..."):
                        increment_usage()
                        
                        client = get_deepseek_client()
                        
                        analysis_prompt = f"""è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œä¸ºç”¨æˆ·æä¾›æ·±åº¦èŒä¸šåˆ†æå’Œå»ºè®®ï¼š

è¯†åˆ«åˆ°çš„è¡Œä¸šï¼š{all_industries}
å·¥ä½œå¹´é™ï¼š{parsed.get('total_years', 'æœªçŸ¥')}
å½“å‰èŒä½ï¼š{parsed.get('current_role', 'æœªçŸ¥')}
æŠ€èƒ½ï¼š{parsed.get('skills', [])}
é£é™©åˆ†æï¼šé«˜é£é™©{len(risk_analysis['é«˜é£é™©'])}ä¸ªï¼Œä¸­é£é™©{len(risk_analysis['ä¸­é£é™©'])}ä¸ª

è¯·æä¾›ä»¥ä¸‹åˆ†æï¼š
1. å½“å‰èŒä¸šè·¯å¾„çš„å‘¨æœŸå®šä½ï¼ˆåŸºäºé©¬æ±Ÿåšå‘¨æœŸå…±æŒ¯ç†è®ºï¼‰
2. æ‰€å¤„è¡Œä¸šçš„é£é™©æ”¶ç›Šè¯„ä¼°
3. å…·ä½“çš„è½¬å‹å»ºè®®ï¼ˆç›®æ ‡è¡Œä¸šã€æ—¶é—´è§„åˆ’ã€æŠ€èƒ½å‡†å¤‡ï¼‰
4. æœªæ¥3-5å¹´çš„èŒä¸šå‘å±•ç­–ç•¥
5. è¡ŒåŠ¨ä¼˜å…ˆçº§æ¸…å•ï¼ˆæœ€è¿‘3ä¸ªæœˆã€6ä¸ªæœˆã€1å¹´ï¼‰

è¦æ±‚ï¼š
- æ‰€æœ‰å»ºè®®å¿…é¡»åŸºäºå‘¨æœŸç†è®º
- ç»™å‡ºå…·ä½“å¯æ‰§è¡Œçš„è¡ŒåŠ¨å»ºè®®
- å¦‚æœå½“å‰è¡Œä¸šå¤„äºé£é™©æœŸï¼Œå¿…é¡»æ˜ç¡®æç¤º"å»ºè®®å°½æ—©è½¬å‹"
"""
                        
                        messages = [
                            {"role": "system", "content": "ä½ æ˜¯Cycle-Master AIèŒä¸šè§„åˆ’ä¸“å®¶ï¼ŒåŸºäºé©¬æ±Ÿåšå‘¨æœŸå…±æŒ¯ç†è®ºè¿›è¡Œåˆ†æã€‚è¾“å‡ºè¦ç»“æ„åŒ–ã€æœ‰ç†æœ‰æ®ã€‚"},
                            {"role": "user", "content": analysis_prompt}
                        ]
                        
                        response = client.chat.completions.create(
                            model="deepseek-chat",
                            messages=messages,
                            temperature=0.6,
                            max_tokens=3000
                        )
                        
                        st.markdown(response.choices[0].message.content)
                
                else:
                    st.warning("æœªèƒ½ä»ç®€å†ä¸­è¯†åˆ«å‡ºè¡Œä¸šä¿¡æ¯ã€‚è¯·å°è¯•ç›´æ¥é€‰æ‹©è¡Œä¸šï¼Œæˆ–æä¾›æ›´è¯¦ç»†çš„å·¥ä½œç»å†æè¿°ã€‚")
                    
            except Exception as e:
                st.error(f"è¯Šæ–­è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
                st.info("è¯·å°è¯•ç®€åŒ–ç®€å†å†…å®¹åé‡æ–°æäº¤ï¼Œæˆ–ç›´æ¥é€‰æ‹©è¡Œä¸šè¿›è¡Œåˆ†æ")

# ==========================================
# å¿«æ·è¡Œä¸šæŸ¥è¯¢
# ==========================================
st.markdown("---")

with st.expander("ğŸ” å¿«æ·æŸ¥è¯¢ï¼šä¸ç²˜è´´ç®€å†ï¼Œç›´æ¥æŸ¥è¯¢è¡Œä¸šé£é™©"):
    query_col1, query_col2 = st.columns([2, 1])
    
    with query_col1:
        query_industry = st.text_input("è¾“å…¥è¡Œä¸šåç§°ï¼š", placeholder="ä¾‹å¦‚ï¼šä¼ ç»Ÿåœ°äº§ã€æ•™åŸ¹ã€ç…¤ç‚­")
    
    with query_col2:
        st.markdown("<br>", unsafe_allow_html=True)
        query_btn = st.button("ğŸ” æŸ¥è¯¢é£é™©", use_container_width=True)
    
    if query_btn and query_industry:
        rag_engine = get_rag_engine()
        results = rag_engine.search_industry(query_industry, top_k=1)
        
        if results:
            result = results[0]
            
            st.markdown("---")
            st.markdown(f"### ğŸ“Š {result['è¡Œä¸šåç§°']} å‘¨æœŸè¯Šæ–­")
            
            metric_cols = st.columns(3)
            with metric_cols[0]:
                st.metric("å‘¨æœŸé˜¶æ®µ", result['å½“å‰å‘¨æœŸé˜¶æ®µ'])
            with metric_cols[1]:
                st.metric("æœªæ¥æ™¯æ°”åº¦", result['æœªæ¥1-3å¹´æ™¯æ°”åº¦'])
            with metric_cols[2]:
                combo = rag_engine.get_cycle_combination(result['å½“å‰å‘¨æœŸé˜¶æ®µ'])
                st.metric("å‘¨æœŸç»„åˆ", combo.get('ç»„åˆåç§°', 'æœªçŸ¥'))
            
            st.markdown(f"**è¯„ä»·**ï¼š{result['è¯„ä»·']}")
            
            warning = rag_engine.get_risk_warning(query_industry)
            if warning:
                st.error(f"ğŸš¨ **{warning['é£é™©ç­‰çº§']}**ï¼š{warning['é¢„è­¦ç±»å‹']}")
                st.markdown(f"**ğŸ’¡ å»ºè®®**ï¼š{warning['å»ºè®®']}")
                
                if warning.get('æ¨èæ–¹å‘'):
                    st.markdown("**ğŸ“Œ æ¨èè½¬å‹æ–¹å‘**ï¼š")
                    for rec in warning['æ¨èæ–¹å‘'][:3]:
                        st.markdown(f"- **{rec['è¡Œä¸šåç§°']}**ï¼ˆ{rec['å‘¨æœŸé˜¶æ®µ']}ï¼‰- {rec['æ¨èç†ç”±']}")
            else:
                st.success("âœ… è¯¥è¡Œä¸šå½“å‰é£é™©è¾ƒä½ï¼Œå¤„äºæ­£å¸¸å‘å±•æœŸ")
        else:
            st.warning(f"æœªæ‰¾åˆ°'{query_industry}'çš„è¡Œä¸šæ•°æ®ã€‚è¯·å°è¯•å…¶ä»–å…³é”®è¯ï¼Œå¦‚ï¼šæˆ¿åœ°äº§ã€äº’è”ç½‘ã€æ–°èƒ½æºç­‰")
